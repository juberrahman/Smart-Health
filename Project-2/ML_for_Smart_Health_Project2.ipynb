{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_for_Smart_Health_Project2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uuydfQ53Z0b"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhcQQMoyiZ8x"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYEjgnn_3lpQ"
      },
      "source": [
        "# Load & Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMPJnjwTlL-X"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Omdena School/ML For Smart Health/mitbih_train.csv', header=None)\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Omdena School/ML For Smart Health/mitbih_test.csv', header=None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJJcLENs6OB_",
        "outputId": "77fa32b1-a555-4f39-a11a-430cdef2bab3"
      },
      "source": [
        "# check for null values\n",
        "print(f\"empty values in train: {train_df.isna().sum().sum()}\")\n",
        "print(f\"empty values in test: {test_df.isna().sum().sum()}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty values in train: 0\n",
            "empty values in test: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpep0IYnyflz"
      },
      "source": [
        "# split the features from the labels\n",
        "train_y = train_df.iloc[:,-1]\n",
        "train_X = train_df.drop(train_df.columns[-1], axis=1)\n",
        "\n",
        "test_y = test_df.iloc[:,-1]\n",
        "test_X = test_df.drop(test_df.columns[-1], axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "WfoLwhwAb6UH",
        "outputId": "e89db3e5-5054-485e-ea2c-ec1394e5c6b0"
      },
      "source": [
        "train_X.describe()\n",
        "# we can see that the data has already been scaled between 0 and 1.\n",
        "# we can also see that the mean values are very small for a lot (but not all) of the features"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "      <td>87554.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.890360</td>\n",
              "      <td>0.758160</td>\n",
              "      <td>0.423972</td>\n",
              "      <td>0.219104</td>\n",
              "      <td>0.201127</td>\n",
              "      <td>0.210399</td>\n",
              "      <td>0.205808</td>\n",
              "      <td>0.201773</td>\n",
              "      <td>0.198691</td>\n",
              "      <td>0.196757</td>\n",
              "      <td>0.198778</td>\n",
              "      <td>0.203550</td>\n",
              "      <td>0.208776</td>\n",
              "      <td>0.212885</td>\n",
              "      <td>0.218393</td>\n",
              "      <td>0.224966</td>\n",
              "      <td>0.231377</td>\n",
              "      <td>0.237123</td>\n",
              "      <td>0.242582</td>\n",
              "      <td>0.247923</td>\n",
              "      <td>0.253749</td>\n",
              "      <td>0.259748</td>\n",
              "      <td>0.266244</td>\n",
              "      <td>0.272734</td>\n",
              "      <td>0.279355</td>\n",
              "      <td>0.285588</td>\n",
              "      <td>0.291808</td>\n",
              "      <td>0.297672</td>\n",
              "      <td>0.303384</td>\n",
              "      <td>0.308795</td>\n",
              "      <td>0.313890</td>\n",
              "      <td>0.318454</td>\n",
              "      <td>0.322087</td>\n",
              "      <td>0.324891</td>\n",
              "      <td>0.326737</td>\n",
              "      <td>0.327817</td>\n",
              "      <td>0.327931</td>\n",
              "      <td>0.326746</td>\n",
              "      <td>0.324326</td>\n",
              "      <td>0.320537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031857</td>\n",
              "      <td>0.030729</td>\n",
              "      <td>0.029582</td>\n",
              "      <td>0.028531</td>\n",
              "      <td>0.027573</td>\n",
              "      <td>0.026875</td>\n",
              "      <td>0.025771</td>\n",
              "      <td>0.024823</td>\n",
              "      <td>0.023932</td>\n",
              "      <td>0.023060</td>\n",
              "      <td>0.022458</td>\n",
              "      <td>0.021809</td>\n",
              "      <td>0.021245</td>\n",
              "      <td>0.020623</td>\n",
              "      <td>0.020026</td>\n",
              "      <td>0.019534</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.018592</td>\n",
              "      <td>0.017664</td>\n",
              "      <td>0.016740</td>\n",
              "      <td>0.015722</td>\n",
              "      <td>0.014402</td>\n",
              "      <td>0.013024</td>\n",
              "      <td>0.011625</td>\n",
              "      <td>0.010262</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>0.008056</td>\n",
              "      <td>0.007278</td>\n",
              "      <td>0.006531</td>\n",
              "      <td>0.005981</td>\n",
              "      <td>0.005479</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.004628</td>\n",
              "      <td>0.004291</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.003681</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>0.002945</td>\n",
              "      <td>0.002807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.240909</td>\n",
              "      <td>0.221813</td>\n",
              "      <td>0.227305</td>\n",
              "      <td>0.206878</td>\n",
              "      <td>0.177058</td>\n",
              "      <td>0.171909</td>\n",
              "      <td>0.178481</td>\n",
              "      <td>0.177240</td>\n",
              "      <td>0.171778</td>\n",
              "      <td>0.168357</td>\n",
              "      <td>0.171796</td>\n",
              "      <td>0.176496</td>\n",
              "      <td>0.180274</td>\n",
              "      <td>0.184101</td>\n",
              "      <td>0.186963</td>\n",
              "      <td>0.190002</td>\n",
              "      <td>0.193899</td>\n",
              "      <td>0.198465</td>\n",
              "      <td>0.202855</td>\n",
              "      <td>0.207166</td>\n",
              "      <td>0.211187</td>\n",
              "      <td>0.214821</td>\n",
              "      <td>0.218450</td>\n",
              "      <td>0.221486</td>\n",
              "      <td>0.224031</td>\n",
              "      <td>0.225848</td>\n",
              "      <td>0.227133</td>\n",
              "      <td>0.227830</td>\n",
              "      <td>0.228436</td>\n",
              "      <td>0.228871</td>\n",
              "      <td>0.228760</td>\n",
              "      <td>0.228393</td>\n",
              "      <td>0.227472</td>\n",
              "      <td>0.226180</td>\n",
              "      <td>0.224659</td>\n",
              "      <td>0.223110</td>\n",
              "      <td>0.221352</td>\n",
              "      <td>0.219258</td>\n",
              "      <td>0.216884</td>\n",
              "      <td>0.214168</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118013</td>\n",
              "      <td>0.116516</td>\n",
              "      <td>0.114463</td>\n",
              "      <td>0.112686</td>\n",
              "      <td>0.111103</td>\n",
              "      <td>0.110513</td>\n",
              "      <td>0.108566</td>\n",
              "      <td>0.106493</td>\n",
              "      <td>0.104591</td>\n",
              "      <td>0.102658</td>\n",
              "      <td>0.101395</td>\n",
              "      <td>0.100201</td>\n",
              "      <td>0.099386</td>\n",
              "      <td>0.098327</td>\n",
              "      <td>0.096635</td>\n",
              "      <td>0.095729</td>\n",
              "      <td>0.095368</td>\n",
              "      <td>0.095055</td>\n",
              "      <td>0.092902</td>\n",
              "      <td>0.091118</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>0.084638</td>\n",
              "      <td>0.079949</td>\n",
              "      <td>0.075307</td>\n",
              "      <td>0.069892</td>\n",
              "      <td>0.063994</td>\n",
              "      <td>0.060074</td>\n",
              "      <td>0.056404</td>\n",
              "      <td>0.052840</td>\n",
              "      <td>0.050006</td>\n",
              "      <td>0.046693</td>\n",
              "      <td>0.044154</td>\n",
              "      <td>0.042089</td>\n",
              "      <td>0.040525</td>\n",
              "      <td>0.038651</td>\n",
              "      <td>0.037193</td>\n",
              "      <td>0.036255</td>\n",
              "      <td>0.034789</td>\n",
              "      <td>0.032865</td>\n",
              "      <td>0.031924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.921922</td>\n",
              "      <td>0.682486</td>\n",
              "      <td>0.250969</td>\n",
              "      <td>0.048458</td>\n",
              "      <td>0.082329</td>\n",
              "      <td>0.088416</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.066116</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.068639</td>\n",
              "      <td>0.070543</td>\n",
              "      <td>0.069182</td>\n",
              "      <td>0.068293</td>\n",
              "      <td>0.067744</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.072993</td>\n",
              "      <td>0.074803</td>\n",
              "      <td>0.075972</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.077872</td>\n",
              "      <td>0.079442</td>\n",
              "      <td>0.081911</td>\n",
              "      <td>0.085938</td>\n",
              "      <td>0.090032</td>\n",
              "      <td>0.094595</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.103960</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.120730</td>\n",
              "      <td>0.127946</td>\n",
              "      <td>0.135962</td>\n",
              "      <td>0.144295</td>\n",
              "      <td>0.151852</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.161035</td>\n",
              "      <td>0.161133</td>\n",
              "      <td>0.159383</td>\n",
              "      <td>0.157343</td>\n",
              "      <td>0.155388</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.991342</td>\n",
              "      <td>0.826013</td>\n",
              "      <td>0.429472</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.147878</td>\n",
              "      <td>0.158798</td>\n",
              "      <td>0.145324</td>\n",
              "      <td>0.144424</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.148734</td>\n",
              "      <td>0.145985</td>\n",
              "      <td>0.148590</td>\n",
              "      <td>0.152951</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.162636</td>\n",
              "      <td>0.169399</td>\n",
              "      <td>0.174603</td>\n",
              "      <td>0.178095</td>\n",
              "      <td>0.182683</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.194595</td>\n",
              "      <td>0.203320</td>\n",
              "      <td>0.212290</td>\n",
              "      <td>0.221656</td>\n",
              "      <td>0.230179</td>\n",
              "      <td>0.238224</td>\n",
              "      <td>0.246450</td>\n",
              "      <td>0.254588</td>\n",
              "      <td>0.262767</td>\n",
              "      <td>0.269640</td>\n",
              "      <td>0.275770</td>\n",
              "      <td>0.279006</td>\n",
              "      <td>0.281879</td>\n",
              "      <td>0.285412</td>\n",
              "      <td>0.288538</td>\n",
              "      <td>0.289701</td>\n",
              "      <td>0.289104</td>\n",
              "      <td>0.284314</td>\n",
              "      <td>0.277630</td>\n",
              "      <td>0.269380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910506</td>\n",
              "      <td>0.578767</td>\n",
              "      <td>0.341727</td>\n",
              "      <td>0.258993</td>\n",
              "      <td>0.287628</td>\n",
              "      <td>0.298237</td>\n",
              "      <td>0.295391</td>\n",
              "      <td>0.290832</td>\n",
              "      <td>0.283636</td>\n",
              "      <td>0.287781</td>\n",
              "      <td>0.293367</td>\n",
              "      <td>0.303079</td>\n",
              "      <td>0.310992</td>\n",
              "      <td>0.316505</td>\n",
              "      <td>0.321809</td>\n",
              "      <td>0.328395</td>\n",
              "      <td>0.337449</td>\n",
              "      <td>0.347711</td>\n",
              "      <td>0.358127</td>\n",
              "      <td>0.369980</td>\n",
              "      <td>0.380402</td>\n",
              "      <td>0.390512</td>\n",
              "      <td>0.397552</td>\n",
              "      <td>0.404295</td>\n",
              "      <td>0.411821</td>\n",
              "      <td>0.421581</td>\n",
              "      <td>0.429688</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.437034</td>\n",
              "      <td>0.437203</td>\n",
              "      <td>0.434868</td>\n",
              "      <td>0.430931</td>\n",
              "      <td>0.427273</td>\n",
              "      <td>0.426084</td>\n",
              "      <td>0.426699</td>\n",
              "      <td>0.428336</td>\n",
              "      <td>0.430604</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.431188</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 187 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0             1    ...           185           186\n",
              "count  87554.000000  87554.000000  ...  87554.000000  87554.000000\n",
              "mean       0.890360      0.758160  ...      0.002945      0.002807\n",
              "std        0.240909      0.221813  ...      0.032865      0.031924\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.921922      0.682486  ...      0.000000      0.000000\n",
              "50%        0.991342      0.826013  ...      0.000000      0.000000\n",
              "75%        1.000000      0.910506  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 187 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCctxIdouf9P"
      },
      "source": [
        "# convert numeric labels to strings so that the models know it's multiclass not a continuous variable\n",
        "train_y.replace([0.0, 1.0, 2.0, 3.0, 4.0], [\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"], inplace=True)\n",
        "test_y.replace([0.0, 1.0, 2.0, 3.0, 4.0], [\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W_e8MM5vYdV",
        "outputId": "2ce13dd0-986a-4483-e179-7336c6977c63"
      },
      "source": [
        "# test how balanced the classes are and whether they are evenly distributed across train and test sets\n",
        "print(f\"train labels distribution:\\n{train_y.value_counts(normalize=True)}\")\n",
        "print(f\"\\n\\ntest labels distribution:\\n{test_y.value_counts(normalize=True)}\")\n",
        "\n",
        "# we can see that they have been stratified\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train labels distribution:\n",
            "beat0    0.827729\n",
            "beat4    0.073452\n",
            "beat2    0.066108\n",
            "beat1    0.025390\n",
            "beat3    0.007321\n",
            "Name: 187, dtype: float64\n",
            "\n",
            "\n",
            "test labels distribution:\n",
            "beat0    0.827608\n",
            "beat4    0.073451\n",
            "beat2    0.066143\n",
            "beat1    0.025397\n",
            "beat3    0.007400\n",
            "Name: 187, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75IKcPZ6mCiP"
      },
      "source": [
        "# Use a RandomForest Classifier to identify the 20 most important features. \n",
        "# Using all 187 makes training take a very long time and does not contribute much more accuracy\n",
        "feature_selector = SelectFromModel(RandomForestClassifier(), max_features=20)\n",
        "feature_selector.fit(train_X, train_y)\n",
        "train_X = feature_selector.transform(train_X)\n",
        "test_X = feature_selector.transform(test_X)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om7XNshE33iR"
      },
      "source": [
        "# Train and Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQfkE6772hgN",
        "outputId": "791780bd-0361-43e8-dcaa-f6bd590c57d5"
      },
      "source": [
        "# get a quick baseline with Naive Bayes\n",
        "model = MultinomialNB() \n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "print(\"confusion matrix: \")\n",
        "confusion_matrix(test_y, y_predicted, labels=[\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 82.72\n",
            "\n",
            "confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18102,     0,    16,     0,     0],\n",
              "       [  556,     0,     0,     0,     0],\n",
              "       [ 1442,     0,     6,     0,     0],\n",
              "       [  162,     0,     0,     0,     0],\n",
              "       [ 1607,     0,     1,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po0f78_6GqSD",
        "outputId": "3ad7301c-5310-43ba-dfe4-17c1d2cbe49f"
      },
      "source": [
        "# train the classifier and evaluate the performance in the test set\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "print(\"confusion matrix: \")\n",
        "confusion_matrix(test_y, y_predicted, labels=[\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 90.11\n",
            "\n",
            "confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17876,    28,   179,     1,    34],\n",
              "       [  405,   127,    24,     0,     0],\n",
              "       [ 1017,     4,   403,     0,    24],\n",
              "       [  138,     0,    24,     0,     0],\n",
              "       [  267,     0,    20,     0,  1321]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIbQffYGHEch",
        "outputId": "e9033214-a5c5-4cb1-9cef-e29a6e5b6b81"
      },
      "source": [
        "model = SVC() # default kernel = rbf\n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "confusion_matrix(test_y, y_predicted)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 95.55\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18024,    57,    31,     0,     6],\n",
              "       [  277,   275,     2,     0,     2],\n",
              "       [  288,     2,  1150,     2,     6],\n",
              "       [  123,     0,    12,    27,     0],\n",
              "       [  158,     0,     8,     0,  1442]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwHcYNyr2Mkx",
        "outputId": "4b2ba603-9037-412d-f56d-6ebb112f081f"
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "print(\"confusion matrix: \")\n",
        "confusion_matrix(test_y, y_predicted, labels=[\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 96.98\n",
            "\n",
            "confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18043,    36,    32,     0,     7],\n",
              "       [  250,   301,     4,     0,     1],\n",
              "       [  155,     0,  1278,     8,     7],\n",
              "       [   59,     0,    15,    88,     0],\n",
              "       [   85,     0,     3,     0,  1520]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCC9Z472wzdC",
        "outputId": "81064945-2775-4810-da0a-9ff0a38a05b8"
      },
      "source": [
        "model = GradientBoostingClassifier()\n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "print(\"confusion matrix: \")\n",
        "confusion_matrix(test_y, y_predicted, labels=[\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 95.67\n",
            "\n",
            "confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17985,    48,    49,    11,    25],\n",
              "       [  282,   260,     4,     0,    10],\n",
              "       [  247,     5,  1170,    15,    11],\n",
              "       [   87,     0,    14,    61,     0],\n",
              "       [  131,     0,     8,     1,  1468]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNm-onTnCpnA"
      },
      "source": [
        "# normalize data to help gradient descent converge quicker\n",
        "train_X = StandardScaler().fit_transform(train_X)\n",
        "test_X = StandardScaler().fit_transform(test_X)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwPW9Xcn2_ug",
        "outputId": "af821af3-7d20-446b-a322-8f078628f2fa"
      },
      "source": [
        "model = MLPClassifier(max_iter=500)\n",
        "model.fit(train_X, train_y)\n",
        "y_predicted= model.predict(test_X)\n",
        "print(f\"accuracy score: {(accuracy_score(test_y, y_predicted) * 100):.2f}\\n\")\n",
        "print(\"confusion matrix: \")\n",
        "confusion_matrix(test_y, y_predicted, labels=[\"beat0\", \"beat1\", \"beat2\", \"beat3\", \"beat4\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 97.22\n",
            "\n",
            "confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17943,    68,    54,    12,    41],\n",
              "       [  209,   340,     3,     3,     1],\n",
              "       [   97,     7,  1313,    15,    16],\n",
              "       [   35,     0,    11,   116,     0],\n",
              "       [   28,     4,     5,     0,  1571]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}